{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Same Seed"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["import torch\n","import random\n","import numpy as np\n","def same_seeds(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","same_seeds(48763)"]},{"cell_type":"markdown","metadata":{"id":"-7n_U7iiKM8U"},"source":["# Read Image"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":367,"status":"ok","timestamp":1718613356362,"user":{"displayName":"蔡東宏","userId":"18434728370449152419"},"user_tz":-480},"id":"3Bjy8dvu8Req"},"outputs":[],"source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","# Define custom dataset\n","class CustomImageDataset(Dataset):\n","    def __init__(self, adult_dir, children_dir, transform=None):\n","        self.adult_dir = adult_dir\n","        self.children_dir = children_dir\n","        self.transform = transform\n","\n","        # Get all image file paths\n","        self.adult_images = [os.path.join(adult_dir, fname) for fname in os.listdir(adult_dir) if fname.endswith('.jpg')]\n","        self.children_images = [os.path.join(children_dir, fname) for fname in os.listdir(children_dir) if fname.endswith('.jpg')]\n","\n","        # Combine adult and children image paths\n","        self.images = self.adult_images + self.children_images\n","\n","        # Labels: adults = 0, children = 1\n","        self.labels = [0] * len(self.adult_images) + [1] * len(self.children_images)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.images[idx]\n","        image = Image.open(img_path).convert(\"RGB\")\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((256,256)),  # Resize images\n","    transforms.ToTensor(),          # Convert to tensor\n","    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n","    transforms.RandomRotation(20),      # Random rotation\n","    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Random color jitter\n","    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # Random erasing\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n","])\n","\n","# Image transformations\n","transform_test = transforms.Compose([\n","    transforms.Resize((256,256)),  # Resize images\n","    transforms.ToTensor(),          # Convert to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n","])\n","\n","batch_size = 16\n","# Dataset and DataLoader\n","adult_train_dir = 'dataset/train/adults'\n","children_train_dir = 'dataset/train/children'\n","adult_test_dir = 'dataset/test/adults'\n","children_test_dir = 'dataset/test/children'\n","dataset_train = CustomImageDataset(adult_train_dir, children_train_dir, transform=transform_train)\n","dataset_test = CustomImageDataset(adult_test_dir, children_test_dir, transform=transform_test)\n","train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["adult_demo_dir = 'dataset_demo/adults'\n","children_demo_dir = 'dataset_demo/children'\n","dataset_demo = CustomImageDataset(adult_demo_dir, children_demo_dir, transform=transform_test)\n","demo_loader = DataLoader(dataset_demo, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"N50FFUWk8Reu"},"source":["# Neural Network"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1718613387944,"user":{"displayName":"蔡東宏","userId":"18434728370449152419"},"user_tz":-480},"id":"Ugst6aUU8Rex"},"outputs":[],"source":["# import torch.nn as nn\n","# import torchvision\n","\n","# class Network(nn.Module):\n","#     def __init__(self, num_classes=2):\n","#         super(Network , self).__init__()\n","#         self.model = torchvision.models.shufflenet_v2_x0_5(pretrained=True)\n","#         self.model = nn.Sequential(*list(self.model.children())[:-3])\n","#         self.dropout = nn.Dropout(p=0.02)\n","#         self.pool = nn.AdaptiveAvgPool2d((4,4))\n","#         self.fc1 = nn.Linear(in_features=96*4*4, out_features=num_classes)\n","#         # self.fc2 = nn.Linear(in_features=4, out_features=num_classes)\n","\n","#     def forward(self, x):\n","#         x = self.model(x)\n","#         x = self.pool(x)\n","#         x = x.view(x.size(0), -1)\n","#         x = self.dropout(x)\n","        \n","#         x = self.fc1(x)\n","        \n","#         # x = self.fc2(x)\n","#         return x\n","\n","import torch.nn as nn\n","import torchvision\n","\n","class Network(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super(Network , self).__init__()\n","        self.model = torchvision.models.shufflenet_v2_x0_5(pretrained=True)\n","        \n","        self.model = nn.Sequential(*list(self.model.children())[:-2])\n","        self.model.add_module('global_avg_pool', nn.AdaptiveAvgPool2d(1))\n","        self.model.add_module('flatten', nn.Flatten())\n","        self.model.add_module('dropout', nn.Dropout(p=0.2))\n","        self.model.add_module('fc', nn.Linear(in_features=192, out_features=2))\n","        \n","\n","        self.dropout = nn.Dropout(p=0.02)\n","        self.fc = nn.Linear(in_features=2, out_features=num_classes)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":341,"status":"ok","timestamp":1718613429129,"user":{"displayName":"蔡東宏","userId":"18434728370449152419"},"user_tz":-480},"id":"QdQGKKej8Rey","outputId":"e1429fa5-df54-4684-a484-9b8666884116"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","FLOPs: 44046916.0, Params: 143528.0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 24, 128, 128]             648\n","       BatchNorm2d-2         [-1, 24, 128, 128]              48\n","              ReLU-3         [-1, 24, 128, 128]               0\n","         MaxPool2d-4           [-1, 24, 64, 64]               0\n","            Conv2d-5           [-1, 24, 32, 32]             216\n","       BatchNorm2d-6           [-1, 24, 32, 32]              48\n","            Conv2d-7           [-1, 24, 32, 32]             576\n","       BatchNorm2d-8           [-1, 24, 32, 32]              48\n","              ReLU-9           [-1, 24, 32, 32]               0\n","           Conv2d-10           [-1, 24, 64, 64]             576\n","      BatchNorm2d-11           [-1, 24, 64, 64]              48\n","             ReLU-12           [-1, 24, 64, 64]               0\n","           Conv2d-13           [-1, 24, 32, 32]             216\n","      BatchNorm2d-14           [-1, 24, 32, 32]              48\n","           Conv2d-15           [-1, 24, 32, 32]             576\n","      BatchNorm2d-16           [-1, 24, 32, 32]              48\n","             ReLU-17           [-1, 24, 32, 32]               0\n"," InvertedResidual-18           [-1, 48, 32, 32]               0\n","           Conv2d-19           [-1, 24, 32, 32]             576\n","      BatchNorm2d-20           [-1, 24, 32, 32]              48\n","             ReLU-21           [-1, 24, 32, 32]               0\n","           Conv2d-22           [-1, 24, 32, 32]             216\n","      BatchNorm2d-23           [-1, 24, 32, 32]              48\n","           Conv2d-24           [-1, 24, 32, 32]             576\n","      BatchNorm2d-25           [-1, 24, 32, 32]              48\n","             ReLU-26           [-1, 24, 32, 32]               0\n"," InvertedResidual-27           [-1, 48, 32, 32]               0\n","           Conv2d-28           [-1, 24, 32, 32]             576\n","      BatchNorm2d-29           [-1, 24, 32, 32]              48\n","             ReLU-30           [-1, 24, 32, 32]               0\n","           Conv2d-31           [-1, 24, 32, 32]             216\n","      BatchNorm2d-32           [-1, 24, 32, 32]              48\n","           Conv2d-33           [-1, 24, 32, 32]             576\n","      BatchNorm2d-34           [-1, 24, 32, 32]              48\n","             ReLU-35           [-1, 24, 32, 32]               0\n"," InvertedResidual-36           [-1, 48, 32, 32]               0\n","           Conv2d-37           [-1, 24, 32, 32]             576\n","      BatchNorm2d-38           [-1, 24, 32, 32]              48\n","             ReLU-39           [-1, 24, 32, 32]               0\n","           Conv2d-40           [-1, 24, 32, 32]             216\n","      BatchNorm2d-41           [-1, 24, 32, 32]              48\n","           Conv2d-42           [-1, 24, 32, 32]             576\n","      BatchNorm2d-43           [-1, 24, 32, 32]              48\n","             ReLU-44           [-1, 24, 32, 32]               0\n"," InvertedResidual-45           [-1, 48, 32, 32]               0\n","           Conv2d-46           [-1, 48, 16, 16]             432\n","      BatchNorm2d-47           [-1, 48, 16, 16]              96\n","           Conv2d-48           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-49           [-1, 48, 16, 16]              96\n","             ReLU-50           [-1, 48, 16, 16]               0\n","           Conv2d-51           [-1, 48, 32, 32]           2,304\n","      BatchNorm2d-52           [-1, 48, 32, 32]              96\n","             ReLU-53           [-1, 48, 32, 32]               0\n","           Conv2d-54           [-1, 48, 16, 16]             432\n","      BatchNorm2d-55           [-1, 48, 16, 16]              96\n","           Conv2d-56           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-57           [-1, 48, 16, 16]              96\n","             ReLU-58           [-1, 48, 16, 16]               0\n"," InvertedResidual-59           [-1, 96, 16, 16]               0\n","           Conv2d-60           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-61           [-1, 48, 16, 16]              96\n","             ReLU-62           [-1, 48, 16, 16]               0\n","           Conv2d-63           [-1, 48, 16, 16]             432\n","      BatchNorm2d-64           [-1, 48, 16, 16]              96\n","           Conv2d-65           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-66           [-1, 48, 16, 16]              96\n","             ReLU-67           [-1, 48, 16, 16]               0\n"," InvertedResidual-68           [-1, 96, 16, 16]               0\n","           Conv2d-69           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-70           [-1, 48, 16, 16]              96\n","             ReLU-71           [-1, 48, 16, 16]               0\n","           Conv2d-72           [-1, 48, 16, 16]             432\n","      BatchNorm2d-73           [-1, 48, 16, 16]              96\n","           Conv2d-74           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-75           [-1, 48, 16, 16]              96\n","             ReLU-76           [-1, 48, 16, 16]               0\n"," InvertedResidual-77           [-1, 96, 16, 16]               0\n","           Conv2d-78           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-79           [-1, 48, 16, 16]              96\n","             ReLU-80           [-1, 48, 16, 16]               0\n","           Conv2d-81           [-1, 48, 16, 16]             432\n","      BatchNorm2d-82           [-1, 48, 16, 16]              96\n","           Conv2d-83           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-84           [-1, 48, 16, 16]              96\n","             ReLU-85           [-1, 48, 16, 16]               0\n"," InvertedResidual-86           [-1, 96, 16, 16]               0\n","           Conv2d-87           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-88           [-1, 48, 16, 16]              96\n","             ReLU-89           [-1, 48, 16, 16]               0\n","           Conv2d-90           [-1, 48, 16, 16]             432\n","      BatchNorm2d-91           [-1, 48, 16, 16]              96\n","           Conv2d-92           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-93           [-1, 48, 16, 16]              96\n","             ReLU-94           [-1, 48, 16, 16]               0\n"," InvertedResidual-95           [-1, 96, 16, 16]               0\n","           Conv2d-96           [-1, 48, 16, 16]           2,304\n","      BatchNorm2d-97           [-1, 48, 16, 16]              96\n","             ReLU-98           [-1, 48, 16, 16]               0\n","           Conv2d-99           [-1, 48, 16, 16]             432\n","     BatchNorm2d-100           [-1, 48, 16, 16]              96\n","          Conv2d-101           [-1, 48, 16, 16]           2,304\n","     BatchNorm2d-102           [-1, 48, 16, 16]              96\n","            ReLU-103           [-1, 48, 16, 16]               0\n","InvertedResidual-104           [-1, 96, 16, 16]               0\n","          Conv2d-105           [-1, 48, 16, 16]           2,304\n","     BatchNorm2d-106           [-1, 48, 16, 16]              96\n","            ReLU-107           [-1, 48, 16, 16]               0\n","          Conv2d-108           [-1, 48, 16, 16]             432\n","     BatchNorm2d-109           [-1, 48, 16, 16]              96\n","          Conv2d-110           [-1, 48, 16, 16]           2,304\n","     BatchNorm2d-111           [-1, 48, 16, 16]              96\n","            ReLU-112           [-1, 48, 16, 16]               0\n","InvertedResidual-113           [-1, 96, 16, 16]               0\n","          Conv2d-114           [-1, 48, 16, 16]           2,304\n","     BatchNorm2d-115           [-1, 48, 16, 16]              96\n","            ReLU-116           [-1, 48, 16, 16]               0\n","          Conv2d-117           [-1, 48, 16, 16]             432\n","     BatchNorm2d-118           [-1, 48, 16, 16]              96\n","          Conv2d-119           [-1, 48, 16, 16]           2,304\n","     BatchNorm2d-120           [-1, 48, 16, 16]              96\n","            ReLU-121           [-1, 48, 16, 16]               0\n","InvertedResidual-122           [-1, 96, 16, 16]               0\n","          Conv2d-123             [-1, 96, 8, 8]             864\n","     BatchNorm2d-124             [-1, 96, 8, 8]             192\n","          Conv2d-125             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-126             [-1, 96, 8, 8]             192\n","            ReLU-127             [-1, 96, 8, 8]               0\n","          Conv2d-128           [-1, 96, 16, 16]           9,216\n","     BatchNorm2d-129           [-1, 96, 16, 16]             192\n","            ReLU-130           [-1, 96, 16, 16]               0\n","          Conv2d-131             [-1, 96, 8, 8]             864\n","     BatchNorm2d-132             [-1, 96, 8, 8]             192\n","          Conv2d-133             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-134             [-1, 96, 8, 8]             192\n","            ReLU-135             [-1, 96, 8, 8]               0\n","InvertedResidual-136            [-1, 192, 8, 8]               0\n","          Conv2d-137             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-138             [-1, 96, 8, 8]             192\n","            ReLU-139             [-1, 96, 8, 8]               0\n","          Conv2d-140             [-1, 96, 8, 8]             864\n","     BatchNorm2d-141             [-1, 96, 8, 8]             192\n","          Conv2d-142             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-143             [-1, 96, 8, 8]             192\n","            ReLU-144             [-1, 96, 8, 8]               0\n","InvertedResidual-145            [-1, 192, 8, 8]               0\n","          Conv2d-146             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-147             [-1, 96, 8, 8]             192\n","            ReLU-148             [-1, 96, 8, 8]               0\n","          Conv2d-149             [-1, 96, 8, 8]             864\n","     BatchNorm2d-150             [-1, 96, 8, 8]             192\n","          Conv2d-151             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-152             [-1, 96, 8, 8]             192\n","            ReLU-153             [-1, 96, 8, 8]               0\n","InvertedResidual-154            [-1, 192, 8, 8]               0\n","          Conv2d-155             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-156             [-1, 96, 8, 8]             192\n","            ReLU-157             [-1, 96, 8, 8]               0\n","          Conv2d-158             [-1, 96, 8, 8]             864\n","     BatchNorm2d-159             [-1, 96, 8, 8]             192\n","          Conv2d-160             [-1, 96, 8, 8]           9,216\n","     BatchNorm2d-161             [-1, 96, 8, 8]             192\n","            ReLU-162             [-1, 96, 8, 8]               0\n","InvertedResidual-163            [-1, 192, 8, 8]               0\n","AdaptiveAvgPool2d-164            [-1, 192, 1, 1]               0\n","         Flatten-165                  [-1, 192]               0\n","         Dropout-166                  [-1, 192]               0\n","          Linear-167                    [-1, 2]             386\n","         Dropout-168                    [-1, 2]               0\n","          Linear-169                    [-1, 2]               6\n","================================================================\n","Total params: 143,528\n","Trainable params: 143,528\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 31.22\n","Params size (MB): 0.55\n","Estimated Total Size (MB): 32.52\n","----------------------------------------------------------------\n"]}],"source":["from torchsummary import summary\n","from torchvision import transforms, models\n","from thop import profile\n","import copy\n","model = Network(num_classes=2)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model = model.to(device)\n","#input_shape = (batch_size, 3, 224, 224)\n","#flops, macs, params = calculate_flops(model=model,input_shape=input_shape,output_as_string=True,output_precision=4)\n","#print(\"FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15, eta_min=0.0000005)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, min_lr=0.0000005)\n","random_tensor = torch.randn(1, 3, 256 ,256).to(device)\n","model_for_profiling = copy.deepcopy(model)\n","\n","# Profile the cloned model without modifying the original model's state_dict\n","model_for_profiling.eval()  # Set the cloned model to evaluation mode\n","with torch.no_grad():\n","    flops, params = profile(model_for_profiling, inputs=(random_tensor,), verbose=False)\n","print(f\"FLOPs: {flops}, Params: {params}\")\n","summary(model,(3,256,256))\n","# 计算 FLOPs\n","# example_input = torch.randn(1, 3, 128, 128)\n","#flops = profile_macs(model, example_input)\n","#print(f\"FLOPs: {flops}\")\n"]},{"cell_type":"markdown","metadata":{"id":"KIIyilz78Rez"},"source":["# Learning"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50, Loss: 0.6947, Accuracy_train: 0.4929, Accuracy_test: 0.5000, Best Accuracy_test: 0.5000\n","Epoch 2/50, Loss: 0.6905, Accuracy_train: 0.5375, Accuracy_test: 0.5250, Best Accuracy_test: 0.5250\n","Epoch 3/50, Loss: 0.6854, Accuracy_train: 0.5696, Accuracy_test: 0.6667, Best Accuracy_test: 0.6667\n","Epoch 4/50, Loss: 0.6752, Accuracy_train: 0.6357, Accuracy_test: 0.6917, Best Accuracy_test: 0.6917\n","Epoch 5/50, Loss: 0.6667, Accuracy_train: 0.6554, Accuracy_test: 0.6917, Best Accuracy_test: 0.6917\n","Epoch 6/50, Loss: 0.6503, Accuracy_train: 0.6964, Accuracy_test: 0.7000, Best Accuracy_test: 0.7000\n","Epoch 7/50, Loss: 0.6309, Accuracy_train: 0.7339, Accuracy_test: 0.7083, Best Accuracy_test: 0.7083\n","Epoch 8/50, Loss: 0.6103, Accuracy_train: 0.7536, Accuracy_test: 0.7333, Best Accuracy_test: 0.7333\n","Epoch 9/50, Loss: 0.5927, Accuracy_train: 0.7643, Accuracy_test: 0.7250, Best Accuracy_test: 0.7333\n","Epoch 10/50, Loss: 0.5715, Accuracy_train: 0.7839, Accuracy_test: 0.7333, Best Accuracy_test: 0.7333\n","Epoch 11/50, Loss: 0.5467, Accuracy_train: 0.7554, Accuracy_test: 0.7500, Best Accuracy_test: 0.7500\n","Epoch 12/50, Loss: 0.5177, Accuracy_train: 0.7964, Accuracy_test: 0.7583, Best Accuracy_test: 0.7583\n","Epoch 13/50, Loss: 0.4847, Accuracy_train: 0.8214, Accuracy_test: 0.7833, Best Accuracy_test: 0.7833\n","Epoch 14/50, Loss: 0.4624, Accuracy_train: 0.8089, Accuracy_test: 0.7833, Best Accuracy_test: 0.7833\n","Epoch 15/50, Loss: 0.4405, Accuracy_train: 0.8321, Accuracy_test: 0.7667, Best Accuracy_test: 0.7833\n","Epoch 16/50, Loss: 0.4155, Accuracy_train: 0.8482, Accuracy_test: 0.7667, Best Accuracy_test: 0.7833\n","Epoch 17/50, Loss: 0.3995, Accuracy_train: 0.8464, Accuracy_test: 0.7667, Best Accuracy_test: 0.7833\n","Epoch 18/50, Loss: 0.3602, Accuracy_train: 0.8714, Accuracy_test: 0.7750, Best Accuracy_test: 0.7833\n","Epoch 19/50, Loss: 0.3470, Accuracy_train: 0.8929, Accuracy_test: 0.7917, Best Accuracy_test: 0.7917\n","Epoch 20/50, Loss: 0.3245, Accuracy_train: 0.8875, Accuracy_test: 0.7917, Best Accuracy_test: 0.7917\n","Epoch 21/50, Loss: 0.2947, Accuracy_train: 0.9036, Accuracy_test: 0.7917, Best Accuracy_test: 0.7917\n","Epoch 22/50, Loss: 0.2915, Accuracy_train: 0.9071, Accuracy_test: 0.8083, Best Accuracy_test: 0.8083\n","Epoch 23/50, Loss: 0.2766, Accuracy_train: 0.9018, Accuracy_test: 0.8250, Best Accuracy_test: 0.8250\n","Epoch 24/50, Loss: 0.2687, Accuracy_train: 0.9214, Accuracy_test: 0.8000, Best Accuracy_test: 0.8250\n","Epoch 25/50, Loss: 0.2324, Accuracy_train: 0.9339, Accuracy_test: 0.8167, Best Accuracy_test: 0.8250\n","Epoch 26/50, Loss: 0.2278, Accuracy_train: 0.9250, Accuracy_test: 0.8250, Best Accuracy_test: 0.8250\n","Epoch 27/50, Loss: 0.2410, Accuracy_train: 0.9143, Accuracy_test: 0.8250, Best Accuracy_test: 0.8250\n","Epoch 28/50, Loss: 0.2068, Accuracy_train: 0.9411, Accuracy_test: 0.8333, Best Accuracy_test: 0.8333\n","Epoch 29/50, Loss: 0.1856, Accuracy_train: 0.9446, Accuracy_test: 0.8250, Best Accuracy_test: 0.8333\n","Epoch 30/50, Loss: 0.1857, Accuracy_train: 0.9446, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 31/50, Loss: 0.1897, Accuracy_train: 0.9357, Accuracy_test: 0.8167, Best Accuracy_test: 0.8333\n","Epoch 32/50, Loss: 0.1708, Accuracy_train: 0.9518, Accuracy_test: 0.7833, Best Accuracy_test: 0.8333\n","Epoch 33/50, Loss: 0.1715, Accuracy_train: 0.9411, Accuracy_test: 0.8167, Best Accuracy_test: 0.8333\n","Epoch 34/50, Loss: 0.1416, Accuracy_train: 0.9643, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 35/50, Loss: 0.1944, Accuracy_train: 0.9304, Accuracy_test: 0.8000, Best Accuracy_test: 0.8333\n","Epoch 36/50, Loss: 0.1572, Accuracy_train: 0.9518, Accuracy_test: 0.7750, Best Accuracy_test: 0.8333\n","Epoch 37/50, Loss: 0.1410, Accuracy_train: 0.9554, Accuracy_test: 0.8167, Best Accuracy_test: 0.8333\n","Epoch 38/50, Loss: 0.1372, Accuracy_train: 0.9607, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 39/50, Loss: 0.1492, Accuracy_train: 0.9429, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 40/50, Loss: 0.1215, Accuracy_train: 0.9714, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 41/50, Loss: 0.1128, Accuracy_train: 0.9732, Accuracy_test: 0.8167, Best Accuracy_test: 0.8333\n","Epoch 42/50, Loss: 0.0889, Accuracy_train: 0.9768, Accuracy_test: 0.7917, Best Accuracy_test: 0.8333\n","Epoch 43/50, Loss: 0.0909, Accuracy_train: 0.9750, Accuracy_test: 0.8083, Best Accuracy_test: 0.8333\n","Epoch 44/50, Loss: 0.1208, Accuracy_train: 0.9607, Accuracy_test: 0.7833, Best Accuracy_test: 0.8333\n","Epoch 45/50, Loss: 0.0941, Accuracy_train: 0.9786, Accuracy_test: 0.7750, Best Accuracy_test: 0.8333\n","Epoch 46/50, Loss: 0.1084, Accuracy_train: 0.9696, Accuracy_test: 0.7833, Best Accuracy_test: 0.8333\n","Epoch 47/50, Loss: 0.0907, Accuracy_train: 0.9768, Accuracy_test: 0.7750, Best Accuracy_test: 0.8333\n","Epoch 48/50, Loss: 0.0953, Accuracy_train: 0.9750, Accuracy_test: 0.8167, Best Accuracy_test: 0.8333\n","Epoch 49/50, Loss: 0.0854, Accuracy_train: 0.9750, Accuracy_test: 0.8000, Best Accuracy_test: 0.8333\n","Epoch 50/50, Loss: 0.0892, Accuracy_train: 0.9732, Accuracy_test: 0.7917, Best Accuracy_test: 0.8333\n","Training complete\n"]}],"source":["# Training loop\n","num_epochs = 50\n","best_acc = 0.0\n","\n","for epoch in range(num_epochs):\n","    # print learning rate\n","    # print(f'{scheduler.get_last_lr()[0]:.6f}')\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    correct_test = 0\n","    total_test = 0\n","    model.train()\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() * inputs.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    scheduler.step(running_loss)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in demo_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_test += labels.size(0)\n","            correct_test += (predicted == labels).sum().item()\n","\n","    epoch_loss_train = running_loss / len(train_loader.dataset)\n","    epoch_acc_train = correct_train / total_train\n","    epoch_acc_test = correct_test / total_test\n","\n","    if epoch_acc_test >= best_acc:\n","        best_acc = epoch_acc_test\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss_train:.4f}, Accuracy_train: {epoch_acc_train:.4f}, Accuracy_test: {epoch_acc_test:.4f}, Best Accuracy_test: {best_acc:.4f}')\n","\n","print('Training complete')"]},{"cell_type":"markdown","metadata":{"id":"ehPyTPbv_3C6"},"source":["# Testing ACC"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1718612868244,"user":{"displayName":"蔡東宏","userId":"18434728370449152419"},"user_tz":-480},"id":"P3e5NKbI8Re0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy_test: 0.8532\n"]}],"source":["model = Network(num_classes=2)\n","model.load_state_dict(torch.load('best_model.pth'))\n","model = model.to(device)\n","model.eval()\n","\n","correct_test = 0\n","total_test = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_test += labels.size(0)\n","        correct_test += (predicted == labels).sum().item()\n","\n","    epoch_acc_test = correct_test / total_test\n","    print(f'Accuracy_test: {epoch_acc_test:.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["# Demo"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy_test: 0.8333\n"]}],"source":["model = Network(num_classes=2)\n","model.load_state_dict(torch.load('best_model.pth'))\n","model = model.to(device)\n","model.eval()\n","\n","correct_test = 0\n","total_test = 0\n","with torch.no_grad():\n","    for inputs, labels in demo_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_test += labels.size(0)\n","        correct_test += (predicted == labels).sum().item()\n","\n","    epoch_acc_test = correct_test / total_test\n","    print(f'Accuracy_test: {epoch_acc_test:.4f}')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
